{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Dependencies"
      ],
      "metadata": {
        "id": "Ry_4vW0w_BN_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2hvJmoE4d6R"
      },
      "outputs": [],
      "source": [
        "# Standard Pytorch Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# RF from sklearn\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Network with 1 hidden layer"
      ],
      "metadata": {
        "id": "RDdKkNqd_G8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple MLP (Multi-Layer Perceptron)\n",
        "class ScalingFactorPredictor(nn.Module):\n",
        "\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(input_size, hidden_size)  # First layer\n",
        "    self.relu = nn.ReLU()                          # Activation function (can try different ones)\n",
        "    self.fc2 = nn.Linear(hidden_size, output_size) # Output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "nTx46js75SV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "Xj2ih6DT_M07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random forest regression model\n",
        "rf_reg = RandomForestRegressor(n_estimators=100)"
      ],
      "metadata": {
        "id": "YYYpcC_B-Ss3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Neural Network"
      ],
      "metadata": {
        "id": "ilV_ZQR7_AbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 1     # Input features (probability p)\n",
        "hidden_size = 4    # Number of neurons in the hidden layer\n",
        "output_size = 1    # Output features (scaling factor)\n",
        "\n",
        "model = SimpleNN(input_size, hidden_size, output_size)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.MSELoss()  # Mean Squared Error Loss Function\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # GD Optimizer\n",
        "\n",
        "epochs = 3\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(<input_data>)\n",
        "    loss = criterion(outputs, y)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "id": "yieXKXLQ-V3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the Random Forest:"
      ],
      "metadata": {
        "id": "W5HWMnIA_9Fa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf.fit(<x_train>, <y_train>)"
      ],
      "metadata": {
        "id": "EAF2P75kAAeC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}